[[../卷积神经网络/卷积层|卷积层]]的输入和输出由*四维张量*组成，张量的每个轴分别对应样本、通道、高度和宽度。而全连接层的输入和输出通常是分别对应于样本和特征的二维张量。

在[[../卷积神经网络/LeNet|LeNet]]、[[深度卷积神经网络(AlexNet)]]、[[使用块的网络(VGG)]]中，最后都是将卷积层压平后，通过全连接层输出输出，这会导致参数的急剧膨胀。
- 对于一个卷积层，其参数为：$输入通道数 \times 输出通道数 \times 卷积窗口大小$。
- 对于一个全连接层，则其参数为：$输入通道数 \times 卷积数据分辨率 \times 全连接分辨率$。
这使得全连接层的参数可以轻松突破百万。

NiN的思路是，替代掉全连接层，具体想法是，如果我们将权重连接到每个空间位置，我们可以将其视为[1x1卷积层](1x1卷积层.md)，从另一个角度看，即将空间维度中的**每个像素视为单个样本**，将**通道维度视为不同特征**。

NiN块以一个普通卷积层开始，后面是两个1×1的卷积层。这两个1×1卷积层充当带有ReLU激活函数的逐像素全连接层。