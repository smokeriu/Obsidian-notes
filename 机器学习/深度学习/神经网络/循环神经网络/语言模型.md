# 文本序列

文本序列与[序列模型](序列模型.md)类似，例如，想要生成`deep learning is fun`这么一串文字，则可以抽象成概率计算：
$$
P(\text{deep}, \text{learning}, \text{is}, \text{fun}) =  P(\text{deep}) P(\text{learning}  \mid  \text{deep}) P(\text{is}  \mid  \text{deep}, \text{learning}) P(\text{fun}  \mid  \text{deep}, \text{learning}, \text{is}).
$$
即，我们需要计算单词的概率， 以及给定前面几个单词后出现某个单词的条件概率。 这些概率本质上就是语言模型的参数。

对于常见的单词，我们可以通过

# N元语法
