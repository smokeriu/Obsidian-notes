交叉熵来源于[[相对熵]]，相对熵描述了两个信息的相关程度，而一般上常使用交叉熵的原因是其更适合运算：
$$
H(P,Q) = -\sum_x P(x) \log Q(x)
$$
其中：
- $P(X)$是目标分布。
- $Q(X)$是实际分布。

特别的，交叉熵$H$越小，则相对熵越小，则说明两个分布越接近。

> 这里的越小，是包含*负号*意义上的越小。即 $\mid H(P,Q) \mid$ 越大。

