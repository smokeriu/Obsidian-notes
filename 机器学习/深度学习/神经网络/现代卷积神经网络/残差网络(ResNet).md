# 思想背景
随着函数的复杂，可能不会使网络更接近理想的结果：
![](Pasted%20image%2020230827173318.png)
对于左侧的情况，随着函数的复杂，其能够学习的范围扩大，但并没有离最佳结果（五角星）更近，所以，我们实际需要的泛函是第二类，即随着函数的复杂，其至少需要包含原来函数的表达范围，这样，更复杂的函数至少不会比原来函数结果更差。

ResNet正是这种思想的具体实现，其主要思想是：

我们假设原有的函数为$y = f(x)$，我们在其基础上增加一层复杂度，得到$g(x) = g(f(x))$，我们修改函数$g$的定义，使其为：$g(x) = g(f(x)) + f(x) = g(y) + y$ 。
这样，则$g(x)$一定包含了$f(x)$的结果。即至少不会比原来差：

> 如果g(x)会导致结果变坏，则随着训练的进行，其得到的权重会逐渐减小（训练是朝着变好的方向进行），则最终，g(x) 

![](Pasted%20image%2020230827175533.png)

# 