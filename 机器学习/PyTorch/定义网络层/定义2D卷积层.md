通过`nn.Conv2d`的方式可以定义卷积层：
```python
nn.Conv2d(
		  in_channels: int,
		  out_channels: int,
		  kernel_size: _size_2_t,
		  bias: bool = True, 
		  padding: Union[str, _size_2_t] = 0, ...
)
```
其中：
- `in_channels`：输入通道数。
- `out_channels`：输出通道数。
- `kernel_size`：卷积核大小。一般是一个二元组。
- `bias`：是否含偏置。
- `padding`：用于[[../../深度学习/神经网络/卷积神经网络/填充|填充]]数据，一般是数字，表示每个维度，每一边填充多大。
	- 设置为1时，表示上下左右各增加一列。
	- 填充值针对输入，不会填充通道。
	- 可以为二元组，则第一个表示上下的扩充值，第二个表示左右的扩充值。

> 关于通道，其理论可参考：[[../../深度学习/神经网络/卷积神经网络/卷积通道|卷积通道]]。

简单而言，卷积是一个3-4维的张量：
- `kernel_szie`：定义了卷积前两维的大小，所以其是一个二元组。
- `in_channels`：定义了卷积第三维的大小。
	- 其一般与输入的第三维大小一样，即我们输入的是一张图像，则这个参数一般设置为3。
- `out_channels`：定义了卷积第四维的大小。
	- 如果设为1，则说明数据经过卷积后输出可以看做是二维矩阵。

# 注意
- 使用padding填充的数据，作用于卷积前的输入上，经过$1*1$的卷积后的*结果*，其边缘由于偏置的非0，而是偏置值。
- 输入张量需要是3维或者4维的，