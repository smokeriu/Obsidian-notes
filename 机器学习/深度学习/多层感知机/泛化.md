# 过拟合
如果有足够多的神经元、层数和训练迭代周期， 模型最终可以在*训练集上达到完美的精度*，此时*测试集的准确性却下降了*，这种情况，即模型在训练数据上拟合的比在潜在分布中更接近的现象称为*过拟合*，用于对抗过拟合的技术称为*正则化*。

# 训练误差和泛化误差
*训练误差*（training error）是指， 模型在训练数据集上计算得到的误差。
*泛化误差*（generalization error）是指， 模型应用在同样从原始样本的分布中抽取的无限多数据样本时，模型误差的期望。在实际中，我们只能通过将模型应用于一个独立的测试集来估计泛化误差， 该测试集由**随机选取**的、**未曾在训练集中出现**的数据样本构成。

# 模型复杂性
