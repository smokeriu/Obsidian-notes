训练模型最麻烦的在于，训练需要时间，而超参数的选择对于结果又至关重要，下面的策略介绍了一些如何选择或调整超参数方法。
# 宽泛策略
宽泛策略的核心在于——缩小训练数据的范围。与减少输入样本数不同之处在于，宽泛策略缩小的是训练模型的类型，例如，在训练数字识别的场景中，我们通过宽泛策略，只训练0和1这两个数字。
这样做的好处时，训练速度得到了成倍的增长，这样我们调整的参数（是否有利于模型训练）能够更快得到反馈。但由于我们缩减了训练样本的类型，这些调整方案并不总是能够适用于原始样本的。

# 学习速率
学习速率会影响代价，一般而言，过小的学习速率会导致学习过慢，而较大的学习速率则会导致"步子迈得太大"，从而错过了"谷底"。

一种调整学习速率的办法是——估算一个初始值$\eta$。
- 如果$\eta$在训练的前面若干回合开始下降，就可以逐步地尝试**增加**它。直到找到一个$\eta$的值使得在开始若干回合代价就开始震荡或者增加。
- 如果$\eta$在训练的前面若干回合就开始震荡或者增加。就可以逐步地尝试**较少**它。直到找到一个$\eta$的值使得在开始若干回合代价就开始下降。
如此，我们可以得到学习速率的阈值的**量级**的估计。

# 提前停止
提前停止表示在 每个回合的最后，我们都要计算验证集上的分类准确率。当准确率不再提升，就终止它。这让选择回合数变得很简单。特别地，也意味着我们不再需要担心显式地**掌握回合数和其他超参数的关联**。而且，这个过程还是**自动的**。另外，提前停止也能够帮助我们**避免过度拟合**。
分类准确率不再提升一般表现为震荡，所以一般是选择一段周期，没有提升则提前停止。不过这个周期，随着训练的进行，应当逐渐加宽，避免某些算法确实存在较长的振荡期。