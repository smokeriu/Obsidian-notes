在机器学习中，所谓的卷积运算，一般指数据的互操作运算，举例而言：
![[assets/Pasted image 20230815172255.png|500]]
上述的卷积操作，将输入与核函数对应位置的数字相乘，并将结果**相加**，得到输出的一个元素。通过计算一圈得到最终的输出。这个例子展示了为什么这个操作被称为*互相关*运算。

# 输出大小
特别的，对于输入形状为$n_h\times n_w$，卷积核形状为$k_h\times k_w$，那么输出形状将是$(n_h-k_h+1) \times (n_w-k_w+1)$。

# 数据丢失
通过观察，这种操作会使输出比输入小一圈，这会一定程度上导致边缘数据的丢失，对于这种情况，可以使用[[填充]]来解决。

