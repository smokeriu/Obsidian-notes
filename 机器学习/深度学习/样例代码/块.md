定义一个块，一般遵循如下的步骤：
1. 接受输入，作为其前向传播函数的参数。
2. 通过前向传播函数来生成输出。
3. 计算其输出关于输入的梯度，可通过其反向传播函数进行访问。
	1. 通常这是自动发生的。我们可以利用框架的自动微分。
4. 存储和访问前向传播计算所需的参数。
5. 根据情况，调整参数。

# 创建块

我们的类需要继承`nn.Module`，并提供初始化函数。下面的函数创建了一个多层感知器，并直接初始化了两个线性层：`hidden`和`out`。

```python
class MLP(nn.Module):
    # 用模型参数声明层。这里，我们声明两个全连接的层
    def __init__(self):
        # 调用MLP的父类Module的构造函数来执行必要的初始化。
        # 这样，在类实例化时也可以指定其他函数参数，例如模型参数params
        super().__init__()
        self.hidden = nn.Linear(20, 256)  # 隐藏层
        self.out = nn.Linear(256, 10)  # 输出层
```

同时，我们需要定义一个前向传播函数：
```python
# 定义模型的前向传播.
def forward(self, X):
    return self.out(F.relu(self.hidden(X)))
```

至此，我们已经完成了一个最简单的块的定义，它由两个线性层组成，他自身也是一个小的神经网络。

# 顺序块
在Torch中，我们可以利用`nn.Sequential`来将多个块线性顺序连接，我们可以参照自定义块的概念，自定义一个`Sequential`：

```python
class MySequential(nn.Module):
    def __init__(self, *args):
        super().__init__()
        for idx, module in enumerate(args):
            # 这里，module是Module子类的一个实例。我们把它保存在'Module'类的成员
            # 变量_modules中。_module的类型是OrderedDict
            self._modules[str(idx)] = module
```
这里，初始化函数增加了一个变长参数，其有一至多个其他块组成，我们将其保存成一个List。

同时，我们也需要定义一个前向传播函数：
```python
def forward(self, X):
    # OrderedDict保证了按照成员添加的顺序遍历它们
    for block in self._modules.values():
        X = block(X)
    return X
```
这里，我们顺序调用保存的其他块，并返回最终的结果。

值得注意的是，这里使用了`_modules`这个自带的Dict，其是由`nn.Module`定义的，遵守这种规定，