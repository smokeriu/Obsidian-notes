在实际应用中，所面对的文本序列长度显然是不固定的，但我们训练网络时，

# 编码器
从技术上讲，编码器将*长度可变*的输入序列转换成*形状固定*的上下文变量$\mathbf{c}$。并且将输入序列的信息在该上下文变量中进行编码。如图所示：
![[assets/Pasted image 20230926154034.png|500]]
假设输入序列是$x_1, \ldots, x_T$，循环神经网络将词元$x_t$的输入特征$\mathbf{x}_t$和上一步的隐状态$\mathbf{h} _{t-1}$转换为这一个时间步的隐状态$\mathbf{h}_t$，用函数$f$来描述这种转换：
$$
\mathbf{h}_t = f(\mathbf{x}_t, \mathbf{h}_{t-1}).
$$
则总之，编码器通过选定的函数$q$，将*所有时间步的隐状态*转换为上下文变量：
$$
\mathbf{c} =  q(\mathbf{h}_1, \ldots, \mathbf{h}_T).
$$
当选择$q(\mathbf{h}_1, \ldots, \mathbf{h}_T) = \mathbf{h}_T$时，上下文变量仅仅是输入序列在最后时间步的隐状态$\mathbf{h}_T$。用图表示如下
