> 激活函数一定是非线性的

# ReLU函数
因为激活函数一定是非线性的，ReLU的思路就是用最简单的方式将线性函数转换为非线性：
$$
\operatorname{ReLU}(x) = \max(x, 0).
$$
其图像如下：
![](Pasted%20image%2020230806165744.png|500)
即，我将$<0$的内容丢弃，那么原有的函数就不再是线性函数。



# Sigmoid函数
# tanh函数
