反向传播，指的是计算神经网络参数[[../../../数学/基础/微积分/梯度公式|梯度]]的方法，该方法根据微积分中的*链式规则*，按相反的顺序从输出层到输入层遍历网络。

假设我们有函数$\mathsf{Y}=f(\mathsf{X})$和$\mathsf{Z}=g(\mathsf{Y})$，利用链式法则，我们可以计算$\mathsf{Z}$关于$\mathsf{X}$的导数：
$$
\frac{\partial \mathsf{Z}}{\partial \mathsf{X}} = \text{prod}\left(\frac{\partial \mathsf{Z}}{\partial \mathsf{Y}}, \frac{\partial \mathsf{Y}}{\partial \mathsf{X}}\right)
$$
> prod是一个抽象的运算符，表示在执行必要的操作（如换位和交换输入位置）后将其参数相乘。

数据经过[[前向传播]]，得到了目标函数$J=L+s$。我们需要利用反向传播，计算各个值的梯度。

第一步，我们计算其对损失函数$\mathbf{L}$和正则化$\mathbf{s}$的梯度：
$$
\frac{\partial J}{\partial L} = 1 \; \text{and} \; \frac{\partial J}{\partial s} = 1.
$$
第二部，根据[[../../../数学/基础/微积分/链式法则|链式法则]]，计算输出层的梯度：
$$
\frac{\partial J}{\partial \mathbf{o}}
= \text{prod}\left(\frac{\partial J}{\partial L}, \frac{\partial L}{\partial \mathbf{o}}\right)
= \frac{\partial L}{\partial \mathbf{o}}
\in \mathbb{R}^q.
$$
> 因为输出$\mathbf{o}$为长度$q$的向量，

第三步，求权重的梯度：
$$
\frac{\partial s}{\partial \mathbf{W}^{(1)}} = \lambda \mathbf{W}^{(1)}
\; \text{and} \;
\frac{\partial s}{\partial \mathbf{W}^{(2)}} = \lambda \mathbf{W}^{(2)}.
$$