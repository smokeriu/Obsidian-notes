多层感知机是最简单的神经网络，由3种类型的层构成：
- 输入层。
- 输出层。
- 隐藏层。

其用图形表示为：
![[assets/Pasted image 20231114190559.png|500]]


# 概述
## 神经元
每一层由多个神经元构成。
## 输入层
输入层即是对输入的高维抽象。比如说一个单词，可以按照字母抽象成数值，最终拼接形成与单词长度一样的一维向量。每个神经元对应这向量中的一个元素。
## 隐藏层
用于对输入层输出的数据的不同特征进行高维抽象，多层感知机的多层就体现在其可以拥有多个隐藏层。
一般而言，每个神经元负责的特征不同，具体负责哪方面的特征是程序自动洗得的。

> 其与输出层特征抽象后的位置相关。
## 输出层
对输出的数据与预期的标签数据进行映射，输出层的每个神经元需要与标签数据抽象的向量一一对应。
例如在识别数字的模型中，对于十进制的数字，显然是一个十分类的问题，标签根据标签值，将对应坐标的元素设置为1，其与元素设置为0；而训练的输出同样生成一个长度为10的向量，我们通过损失函数，可以计算这两个向量的差异性，训练的目的就是让程序根据*输入*与*标签*的关系，降低这个差异性，使得最终输出的向量尽可能接近标签对应的向量。
## 前向传播
一般而言，层在接受到输入后，会经过一个线性变换：
$$
out = f(input) = w * input + b
$$
之后再经过[[../基础知识/激活函数|激活函数]]处理后作为下一层的输入：
$$
input2 = \alpha(output)
$$
当数据到达输出层时，再通过[[../基础知识/损失函数|损失函数]]计算损失值，通过反向传播优化参数，从而训练模型。

## 全连接
多层感知机是全连接的，即每个上游神经元，都会连向下一层每一个神经元。因此，多层感知机又叫作：
- 全连接神经网络。
- 稠密连接网络。（Dense）
- 线性层。（Linear）
