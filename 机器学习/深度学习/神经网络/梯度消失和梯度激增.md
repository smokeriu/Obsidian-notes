# 梯度消失
随着我们增加神经网络的隐藏层数量，我们会发现并没有对学习产生正面影响，这一般是梯度消失引起的。
## 原因
其实主要是用[[感知器和神经元#S型神经元]]引起的，对$\sigma$函数求倒数，会得到ru


# 梯度激增
与梯度消失相对应的就是梯度激增，