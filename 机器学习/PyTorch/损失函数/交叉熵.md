---
tags:
  - 损失函数
  - 交叉熵
---
PyTorch通过`nn.cross_entropy`来使用交叉熵损失函数，用来判定实际的输出与期望的输出的接近程度。交叉熵的值越小，两个概率分布就越接近。

定义函数的主要参数有：
- weight：
	- Tensor, optional。
	- 必须是一个1维的tensor，长度为类别数，每个值对应每一类的权重。
- reduction：
	- 最终的输出类型，默认为`mean`。
	- 可以为`none`或`sum`。

使用函数时需要传入input与target，需要特别注意：
- input：
	- 需要时**原始的**预测输出，*未经过`softmax`或者`normalized`的*。原因是这个函数会首先对输入的原始得分进行`softmax`，所以必须保证输入的是每一类的原始得分。
		- 不能写成`[0.2, 0.36, 0.44]`这种softmax之后的或者`[0, 1, 0]`这种`one-hot`编码。
- target：
	- 不能是`one-hot`标签，直接输入每个例子对应的类别编号就行了