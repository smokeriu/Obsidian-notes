在实际中，我们需要将输入的数字图像转换为数字，这些数据来自于MNIST数据集，均为$28 \times 28$的灰度图像，所以，我们可将输入看做是$28 \times 28 = 784$维的向量。而输出则是十维的，$y(x) = (0,0,1,...,0)^{T}$，为一表示这个数字可能为对应的(坐标)代表的数字。
我们实际的目的，就是找到合适的权重$w$和偏置$b$，来使结果尽可能准确。为了量化目标，我们需要代价函数：
$$
\symbfit{C}(w,b) 
\equiv 
\frac{1}{2n} \sum_{x}{}\vert\vert y(x) -a \vert\vert ^2
$$
其中，$n$为训练的输入数据个数，$a$表示输入x时的输出向量。符号$\vert\vert \vec{v} \vert\vert$指向量$\vec{v}$的模。上述C被称为**二次**代价函数，也被称为**均方误差**或者**MSE**。其是一个非负数，所以其约趋近于0，则说明结果越准确。
> 使用二次的原因是，我们想放大对权重和偏置的微小改变对结果的影响。

# 梯度下降
使用[[../../../数学/基础/微积分/向量场、梯度、势能#梯度|向量场、梯度、势能]]下降的方法，找到极值点。因为我们希望找到最小的$\symbfit{C}$，所以我们希望其变化率$\Delta{\symbfit{C}}$为负。

进一步，我们先将$\symbfit{C}$简化，想象其为两个向量组成的函数。当我们在一个点，将其向$\vec{v_1}$和$\vec{v_2}$移动很小的量，可以表示为：
$$
\Delta{\symbfit{C}} 
\approx 
\frac{\partial{\symbfit{C}}}{\partial{v_1}} \Delta{v_1}
+
\frac{\partial{\symbfit{C}}}{\partial{v_2}} \Delta{v_2}
$$
特别的，我们定义一个$\Delta{v} \equiv (\Delta{v_1}, \Delta{v_2})^T$，为$\vec{v}$变化的向量。同时，我们对梯度进行定义：
$$
\nabla{\symbfit{C}} \equiv
(\frac{\partial{\symbfit{C}}}{\partial{v_1}},\frac{\partial{\symbfit{C}}}{\partial{v_2}})^T
$$
则，我们可以将$\Delta{\symbfit{C}}$改写为：
$$
\Delta{\symbfit{C}} 
\approx
\nabla{\symbfit{C}} · \Delta{v}
$$
我们的目的是选取何时的$\Delta{v}$，则选取：
$$
\Delta{v} = -\eta \nabla{\symbfit{C}}
$$
> $\eta$为学习速率，为一个很小的正数。

将上述两个方程结合，得到：
$$
\Delta{\symbfit{C}} 
\approx
\nabla{\symbfit{C}} · -\eta \nabla{\symbfit{C}}
=
-\eta · \vert\vert \nabla{\symbfit{C}} \vert\vert ^ 2
$$
所以，我们可以得到具体的梯度下降方程：
$$
v \to v^{'} = v - 
$$