在机器学习中，我们通常在评估几个候选模型后选择最终的模型。 这个过程叫做*模型选择*。一般会使用验证集来选择模型
# 验证集
一般而言，我们将数据分为三份，互不交叉：
- 训练集，用于训练数据。
- 验证集，用于评估模型的表现，并可根据表现来调整超参数。提高模型在验证集上的表现。
- 测试集，用于评估模型的泛化能力。模型调整超参数不应该让测试集介入。

验证集通常用于*调整超参数*，根据几组模型*验证集上的表现*决定哪组超参数拥有最好的性能。，还可以用来监控模型是否发生过拟合，一般来说验证集表现稳定后，若继续训练，训练集表现还会继续上升，但是验证集会出现不升反降的情况，这样一般就发生了过拟合。

> 测试数据集：测试模型的泛化能力。
> 验证集：通常用于调整超参数，防止过拟合。

注意，测试数据集最大的特点是：不参与调参，即我们的超参数结果不应当参考测试数据集。如果模型在测试集上泛化能力很差，而我们之后根据测试集来调整参数，则测试数据集会成为验证集。

# K折交叉验证
一种情况是数据量很少，导致我们无法构建足够的验证集，一种方法被称为K折交叉验证。
1. 将原始训练数据被分成`K`个不重叠的子集。 
2. 然后执行K次模型训练和验证，每次在`K-1`个子集上进行训练， 并在剩余的一个子集（在该轮中没有用于训练的子集）上进行验证。
3. 通过对`K`次实验的结果取平均来估计训练和验证误差。