# 自回归模型
部分数据随着时间而变化，反映到数据上，是序列数据，则假如我们在时刻$t$观察数据，则我们会得到$T$个*不独立*的*离散*的随机变量，即：
$$
(x_1, x_2, \ldots, x_T) \sim p(\mathbf{x})
$$
其中：
- $p(\mathbf{x})$表示联合[[../../../../数学/基础/概率论/分布函数|分布函数]]。

根据[[../../../../数学/基础/概率论/马尔科夫链|马尔科夫链]]，则有：
$$
p(\mathbf{x}) = p(x_1) \cdot p(x_2 \mid x_1) \cdot \ldots p(x_T \mid x_1, \ldots x_{T-1})
$$
我们最终的目的是得到$p(x_t \mid x_1, \ldots, x_{t-1})$，则我们可以对已知的$x_1, \ldots x_{t-1}$用函数建模，即$f(x_1, \ldots x_{t-1})$。则有：
$$
x_t \sim P(x_t \mid f(x_1, \ldots x_{t-1}))
$$
> 这里表示的是各种$x_t$出现的分布情况。

我们称这个为自回归模型。

# 马尔科夫假设
由于时间是无限增长的，这会带来数据的无限增长，我们假设当前数据只与$\tau$个过去数据点相关，则公式可以改写为：
$$
p(x_t \mid x_{t-\tau}, \ldots x_{t-1})
$$
特别的，当$\tau = 1$时，得到*一阶马尔可夫模型*，即：
$$
P(x_1, \ldots, x_T) = \prod_{t=1}^T P(x_t \mid x_{t-1}) \text{ 当 } P(x_1 \mid x_0) = P(x_1).
$$
> 公式的物理含义是，在$x_{t+1}$时刻状态的条件概率，仅依赖于前一刻的状态$x_{t}$。

另外，利用马尔科夫假设，由于数据是离散的，根据[[../../../../数学/基础/概率论/边缘分布#离散边缘分布|边缘分布]]和[[../../../../数学/基础/概率论/条件概率|条件概率]]，我们可以计算$P(x_{t+1} \mid x_{t-1})$，即：
$$
\begin{split}\begin{aligned}
P(x_{t+1} \mid x_{t-1})
&= \frac{P({x_{t-1}, x_{t+1})}}{P(x_{t-1})} \\
&= \frac{\sum_{x_t} P(x_{t+1}, x_t, x_{t-1})}{P(x_{t-1})}\\
&= \frac{\sum_{x_t} P(x_{t+1} \mid x_t, x_{t-1}) P(x_t, x_{t-1})}{P(x_{t-1})}\\
&= \sum_{x_t} P(x_{t+1} \mid x_t) P(x_t \mid x_{t-1})
\end{aligned}\end{split}
$$


# 潜变量模型
引入潜变量来表示过去的信息：
$$
h_t = f(x_1, \ldots x_{t-1})
$$
则$x_t = p(x_t \mid h_t)$
> 本质上，潜变量是用来概括历史信息的*总结*。

通过引入潜变量，我们可以拆解为两个模型：
1. 计算$h_t$，并根据$x_t$更新$h_{t+1}$的模型。
2. 根据$h_t$和历史数据，推测$x_t$的模型。

# k步预测
对于直到$x_t$的观测序列，其在$t+k$处的预测输出$\hat{x_{t+k}}$，我们称为k步预测。对于一个简单的序列模型，我们假设模型训练完后，不会随着$x_{t+k}$而更新，则