逻辑回归，指使用数学来找出**两个**数据因子之间的关系，一般用于解决*二分类*的问题。

# 模型函数
逻辑回归一般是由线性回归和[激活函数](激活函数.md)组成。公式为：
$$
\hat{y} = \sigma(w^T x + b)
$$
其中：
- $\sigma$为激活函数。
- $w$为权重参数。是一个学习参数。
- $b$为偏置。是一个学习参数。
- $\hat{y}$表示模型输出的结果，且有：$\hat{y} \in (0,1)$。


# 损失函数
在二分类问题中，显然我们要预测的结果是0或1，本质上可以认为这是一个概率问题：已知观测数据，得到这个结果的*概率*是多少。
则对于一条输入，结果为1的概率：
$$
P(Target = 1 \mid x_i) = \hat{y_i}
$$
而对于一条输入，结果为0的概率：
$$
P(Target = 0 \mid x_i) = 1 - \hat{y_i}
$$
其中：
- $\hat{y_i}$表示对于第$i$个样本，模型输出的值。

显然，对于深度学习，是在已知样本结果的基础上，来推测模型应该长什么样，则可以翻译为[似然函数](似然函数.md)，则对于多个输入，则损失函数有：
$$
L(w) = \prod \hat{y_i}^{y_i} (1 - \hat{y_i})^{1-y_i}
$$
