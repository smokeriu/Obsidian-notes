在线性神经网络中，我们处理图像是直接平铺开，这对于小图片还行，然而对于稍大一点的照片，例如百万级像素的照片，如果按照线性神经的办法，则会拥有一百万个维度。

卷积的概念，来源于不变性：
- 平移不变性：不管检测对象出现在图像中的哪个位置，神经网络的前面几层应该对相同的图像区域具有相似的反应。
	- 即**不管它的输入是如何平移的，系统产生完全相同的响应（输出）。**。
- 局部性：神经网络的前面几层应该只探索输入图像中的局部区域，而不过度在意图像中相隔较远区域的关系。


# 多层感知机的限制
首先，[多层感知机](多层感知机.md)的输入是二维图像$\mathbf{X}$，其*隐藏表示*$\mathbf{H}$在数学上是一个矩阵，在代码中表示为二维张量。为了方便理解，我们可以认为，无论是输入还是隐藏表示都拥有空间结构。

> 隐藏表示，即输入经过处理后的输出。

使用$[\mathbf{X}]_{i, j}$和$[\mathbf{H}]_{i, j}$分别表示输入图像和隐藏表示中位置$(i,j)$处的像素。为了使每个隐藏神经元都能接收到每个输入像素的信息，我们将参数从权重矩阵替换成*四阶*权重张量$\mathsf{W}$，并使用$\mathbf{U}$表示偏置参数，则可以得到公式：
$$
\begin{split}\begin{aligned} \left[\mathbf{H}\right]_{i, j} &= [\mathbf{U}]_{i, j} + \sum_k \sum_l[\mathsf{W}]_{i, j, k, l}  [\mathbf{X}]_{k, l}\\ &=  [\mathbf{U}]_{i, j} +
\sum_a \sum_b [\mathsf{V}]_{i, j, a, b}  [\mathbf{X}]_{i+a, j+b}.\end{aligned}\end{split}
$$
其中，第二个公式使用$a$和$b$替换了$k$和$l$，他们的关系是：
- $k = i+a$。
- $l = j+b$。
这么做的目的是，我们将输入和输出通过$(i,j)$坐标联系了起来，对于隐藏表示中任意给定位置$(i,j)$处的像素值$[\mathbf{H}]_{i, j}$，可以通过在$\mathbf{X}$中以$(i,j)$为中心对像素进行加权求和得到，而加权权重正是$[\mathsf{V}]_{i, j, a, b}$。

> 这里之所以是以$(i,j)$为中心，是因为我们选择的具体的$[\mathbf{X}]_{i+a, j+b}$是由$(i,j)$变换得来的，而由于我们定义的$(k,j)$求和包含了$\mathbf{X}$上的每一个像素。

> 进一步而言，对于不同的$(i,j)$取值，$(a,b)$取值会不一样。

## 平移不变形
这意味着检测对象在输入$\mathbf{X}$中的平移，应该仅导致隐藏表示$\mathbf{H}$中的平移。

> 这是卷积的定义。

也就是说，**$\mathbf{U}$和$\mathbf{V}$实际上不依赖于$(i,j)$的值**。即$[\mathsf{V}]_{i, j, a, b} = [\mathbf{V}]_{a, b}$。并且偏置是一个*常数*，则上述公式简化为：
$$
[\mathbf{H}]_{i, j} = u + \sum_a\sum_b [\mathbf{V}]_{a, b} [\mathbf{X}]_{i+a, j+b}.
$$
我们是在使用系数$[\mathbf{V}]_{a, b}$对位置$(i, j)$附近的像素$(i+a, j+b)$进行加权得到$[\mathbf{H}]_{i, j}$。
## 局部性
这意味着，为了收集用来训练参数$[\mathbf{H}]_{i, j}$的相关信息，我们不应偏离到距$(i, j)$很远的地方，我们可以将这些偏离过远的数据看做是无效的，则有：
$$
[\mathbf{H}]_{i, j} = u + \sum_{a = -\Delta}^{\Delta} \sum_{b = -\Delta}^{\Delta} [\mathbf{V}]_{a, b}  [\mathbf{X}]_{i+a, j+b}.
$$
简而言之， 这是是一个*卷积层*公式，而**卷积神经网络是包含卷积层的一类特殊的神经网络**。
其中：
- $\mathbf{V}$被称为*卷积核（convolution kernel）* 或 *滤波器（filter）*。亦或简单地称之为该*卷积层的权重*，是一个可以学习的参数。

以前，多层感知机可能需要数十亿个参数来表示网络中的一层，而现在卷积神经网络通常只需要几百个参数，而且不需要改变输入或隐藏表示的维数。参数大幅减少的*代价*是，我们的特征现在是平移不变的，并且当确定每个隐藏活性值时，每一层只包含局部的信息。