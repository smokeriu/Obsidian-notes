训练程序中，主要有如下内容：
1. 定期将模型参数保存。
2. 训练模型。

# 模型参数检查点保存和读取
因为涉及到定期保存参数，所以需要一个参数来确定是重新训练还是从头开始训练，使用的是python的`argparse`。
```python
parse = ArgumentParser()  
parse.add_argument(  
    '--c',  
    default=None,  
    type=str,  
    help='train from scratch or resume ',  
)  
  
arg = parse.parse_args()
```
如果从checkpoint读取，则：
```python
if arg.c:  
    checkpoint = torch.load(arg.c)  
    model.load_state_dict(checkpoint['model_state_dict'])  
    opt.load_state_dict(checkpoint['optimizer_state_dict'])  
    start_epoch = checkpoint['epoch']
```
其中，checkpoint为保存的数据，是一个dict。这里主要加载了：
- 模型数据。
- 优化器数据。
- 训练的epoch数。

对应的，其保存函数定义为：
```python
def save_checkpoint(model_: nn.Module, epoch_, opt_: torch.optim.Optimizer, path):  
    save_dict = {  
        'epoch': epoch_,  
        'model_state_dict': model_.state_dict(),  
        'optimizer_state_dict': opt_.state_dict(),  
    }  
    torch.save(save_dict, path)
```

# 训练内容定义
开始训练前，需要如下内容：
- 模型。
- 训练数据。
- 优化器。
- 损失函数。
- 训练进度：记录到第几个epoch，共进行了多少次训练。
则：
```python
# 模型
model = BanknoteClassificationModel().to(HP.device)
# 训练数据
train_dataset = dataset_banknote.BanknoteDataset(HP.trainset_path)
train_loader = DataLoader(train_dataset, 
						  batch_size=HP.batch_size, shuffle=True, drop_last=True)
# 优化器
opt = torch.optim.Adam(model.parameters(), lr=HP.init_lr)
# 损失函数
criterion = nn.CrossEntropyLoss()
# 训练进度
start_epoch, step = 0, 0
```

#  训练
开始训练前，需要将模型转换为训练模式：
```python
model.train()
```
实际训练中，我们将数据划分为多个批次的数据，并训练多个epoch次：
```python
for epoch in range(start_epoch, HP.epochs):
  total_step = len(train_loader) / HP.batch_size
  print("Start epoch %d. steps: %d" % (epoch, total_step))
  for batch in train_loader:
```
开启每一个batch训练前，需要经过如下步骤：
1. 清空梯度。
2. 前向传播。
3. 计算损失。
4. 反向传播。
5. 使用优化器优化参数。
```python
x, y = batch  
model.zero_grad()  
pred = model(x)  
loss = criterion(pred, y)  
loss.backward()  
opt.step()
```


# 评估模型
训练过程中，需要定期对训练结果进行评估验证，从而使我们可以调整超参数。评估的逻辑和训练类似，通过将评估数据集前向传播，计算损失。
特别的，评估模型前，需要将模型转换为评估模式，并在结束评估后转换回训练模式：
```python
def evaluate(model_, dev_loader, cri) -> float:  
    # 进入评估模式  
    model_.eval()  
    sum_loss = 0.  
    with torch.no_grad():  
        for batch in dev_loader:  
            x, y = batch  
            # 前向传播
            pred = model_(x)  
            # 计算总损失
            sum_loss += cri(pred, y)  
    # 返回训练模式
    model_.train()  
    return sum_loss/len(dev_loader)
```