# 独热编码
与用于分类的神经网络一样，我们仍然需要通过[[../../通用知识/独热编码|独热编码]]来对数据进行处理，使其对计算机更加友好，也便于后续计算相似度。

简言之，将每个索引映射为相互不同的*单位向量*： 假设词表中不同词元的数目为$N$，则词元的索引范围为0到$N-1$。我们构建一个长度为$N$的全0向量，对于索引为$i$的词元，设置其向量第$i$处值为1。

参考：[[../../../PyTorch/基础/独热编码|PyTorch独热编码]]

# 参数初始化
初始参数化时，有两个主要的参数：
- 词元个数`vocab_size`。
- 隐藏层输出个数`num_hiddens`。
其中，输入和输出的维度是一样的，因为二者的词元取值范围是一样的，由于我们对数据进行了独热编码，则输入和输出的维度数都等于词元个数。
```python
num_inputs = num_outputs = vocab_size
```
接着，我们需要初始化[[循环神经网络#循环层]]的参数：
```python
# 输入权重
# 输入维度是num_inputs，输出num_hiddens
W_xh = normal((num_inputs, num_hiddens))
# 隐变量权重。
# 因为隐变量的输入是上一个时间步隐藏层的输出，所以，其输入维度是num_hiddens
W_hh = normal((num_hiddens, num_hiddens))
# 偏置
b_h = torch.zeros(num_hiddens, device=device)
```
