在[[熵]]中，我们讨论了离散的概率分布下，熵的计算公式。对于连续变量$x$，假设[[../概率论/分布函数|概率分布]]为$P(x)$，则其熵公式为：
$$
Entropy = - \int P(x) \log_2 P(x) dx
$$
由于熵的本质是都是计算*负的可能性的对数*的期望，我们将熵的公式统一简写如下：
$$
H = \mathbb{E}_{x \sim P} [-\log P(x)]
$$
其中：
- $H$为熵的简写。
- $x \sim P$表示使用概率分布来计算期望

# 熵的估计
很多时候，我们无法知道事件的概率，获得熵则需要估计。

比如需要预测天气，假设对天气进行了一定的观察后，可以得到了天气的概率分布函数$P(x)$。在进行观测之前，拥有一个*预估*的概率分布函数$Q(x)$。则我们利用$Q(x)$计算熵，但显然，这个与实际的真是熵差距会很大，