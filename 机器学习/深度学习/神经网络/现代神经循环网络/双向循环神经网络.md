在序列学习中，我们以往假设的目标是： 在给定观测的情况下 （例如，在时间序列的上下文中或在语言模型的上下文中）， 对下一个输出进行建模。 虽然这是一个典型情景，但不是唯一的。
例如上一个句子开头是Green，但我们需要通过*下文*才能够直到Green代表的是一个人还是绿色。

# 架构和定义
在系统设计上，我们需要下一个时间步的隐状态：
![[assets/Pasted image 20230925145257.png|500]]
对于给定的时间步$t$，假设有一组输入$\mathbf{X}_t \in \mathbb{R}^{n \times d}$（其中，$n$表示样本数，$d$表示输入数）。另设该时间步的前向和反向隐状态分别为$\overrightarrow{\mathbf{H}}_t \in \mathbb{R}^{n \times h}$和$\overleftarrow{\mathbf{H}}_t \in \mathbb{R}^{n \times h}$。则有：
$$
\begin{split}\begin{aligned}
\overrightarrow{\mathbf{H}}_t &= \phi(\mathbf{X}_t \mathbf{W}_{xh}^{(f)} + \overrightarrow{\mathbf{H}}_{t-1} \mathbf{W}_{hh}^{(f)}  + \mathbf{b}_h^{(f)}),\\
\overleftarrow{\mathbf{H}}_t &= \phi(\mathbf{X}_t \mathbf{W}_{xh}^{(b)} + \overleftarrow{\mathbf{H}}_{t+1} \mathbf{W}_{hh}^{(b)}  + \mathbf{b}_h^{(b)}),
\end{aligned}\end{split}
$$



# 隐马尔可夫模型的动态规划
假设在任意时间步$t$，假设存在某个隐变量$h_t$，通过概率$P(x_t \mid h_t)$来控制我们观察到的$x_t$。此外，任何$h_t \to h_{t+1}$转移都是有一些状态转移概率$P(h_{t+1} \mid h_t)$给出的，则称为**隐马尔可夫模型**，如图所示：
![](Pasted%20image%2020230924122059.png)
因此，对于有$T$个观测值的序列（一般指长度为$T$的序列），我们在观测状态和隐状态上具有以下联合概率分布可以通过公式给出：
$$
P(x_1, \ldots, x_T, h_1, \ldots, h_T) = \prod_{t=1}^T P(h_t \mid h_{t-1}) P(x_t \mid h_t), \text{ where } P(h_1 \mid h_0) = P(h_1)
$$

假设通过$x_{-j}$表示非时间步$j$的观测所组成的向量，即：
$$
x_{-j} = (x_1, \ldots, x_{j-1}, x_{j+1}, \ldots, x_{T})
$$
显然，目标其实是计算$P(x_j \mid x_{-j})$。由于没有观测到时间步$j$，$P(x_j \mid x_{-j})$不含隐变量，因此考虑对$h_1, \ldots, h_T$选择构成的*所有可能*的组合进行求和。而如果任何$h_i$可以接受$k$个（有限）不同的值，意味着需要对$k^T$个项求和，这里就需要引入**动态规划**。
我们将求和公式逐项展开，得到：
$$
\begin{split}\begin{aligned}
    &P(x_1, \ldots, x_T) \\
    =& \sum_{h_1, \ldots, h_T} P(x_1, \ldots, x_T, h_1, \ldots, h_T) \\
    =& \sum_{h_1, \ldots, h_T} \prod_{t=1}^T P(h_t \mid h_{t-1}) P(x_t \mid h_t) \\
    =& \sum_{h_2, \ldots, h_T} \underbrace{\left[\sum_{h_1} P(h_1) P(x_1 \mid h_1) P(h_2 \mid h_1)\right]}_{\pi_2(h_2) \stackrel{\mathrm{def}}{=}}
    P(x_2 \mid h_2) \prod_{t=3}^T P(h_t \mid h_{t-1}) P(x_t \mid h_t) \\
    =& \sum_{h_3, \ldots, h_T} \underbrace{\left[\sum_{h_2} \pi_2(h_2) P(x_2 \mid h_2) P(h_3 \mid h_2)\right]}_{\pi_3(h_3)\stackrel{\mathrm{def}}{=}}
    P(x_3 \mid h_3) \prod_{t=4}^T P(h_t \mid h_{t-1}) P(x_t \mid h_t)\\
    =& \dots \\
    =& \sum_{h_T} \pi_T(h_T) P(x_T \mid h_T).
\end{aligned}\end{split}
$$
其中，前向回归写为：
$$
\pi_{t+1}(h_{t+1}) = \sum_{h_t} \pi_t(h_t) P(x_t \mid h_t) P(h_{t+1} \mid h_t).
$$
初始化第一项为$\pi_1(h_1) = P(h_1)$。

