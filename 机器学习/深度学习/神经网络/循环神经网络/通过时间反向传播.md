深度学习利用[[../../多层感知机/反向传播|反向传播]]来完成对参数的更新，不过在循环神经网络中，直接使用反向传播，很容易遇到传播链过长的问题，因为$h_t$由$x_t$于$h_{t-1}$生成，这意味着序列末尾元素会反向传播到序列的第一个元素。
在[[循环神经网络]]中，我们知道计算$H_t$的公式为：
$$
\mathbf{H}_t = \phi(\mathbf{X}_t \mathbf{W}_{xh} + \mathbf{H}_{t-1} \mathbf{W}_{hh}  + \mathbf{b}_h)
$$
其中，$\mathbf{W}_{hh}$是隐变量的权重cj'u

而通过时间反向传播，实际上是循环神经网络中反向传播技术的一个特定应用。

# 截断时间步
比较常见的方案是，*固定*在$\tau$步后截断传播。 这样做导致该模型主要侧重于短期影响，而不是长期影响。 这在现实中是可取的，因为它会将估计值偏向更简单和更稳定的模型。

## 随机截断
进一步，我们可以用一个随机变量替换$\partial h_t/\partial w_h$，