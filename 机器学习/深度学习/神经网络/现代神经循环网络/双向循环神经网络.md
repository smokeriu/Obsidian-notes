在序列学习中，我们以往假设的目标是： 在给定观测的情况下 （例如，在时间序列的上下文中或在语言模型的上下文中）， 对下一个输出进行建模。 虽然这是一个典型情景，但不是唯一的。
例如上一个句子开头是Green，但我们需要通过*下文*才能够直到Green代表的是一个人还是绿色。


# 隐马尔可夫模型的动态规划
假设在任意时间步$t$，假设存在某个隐变量$h_t$，通过概率$P(x_t \mid h_t)$来控制我们观察到的$x_t$。此外，任何$h_t \to h_{t+1}$转移都是有一些状态转移概率$P(h_{t+1} \mid h_t)$给出的，则称为**隐马尔可夫模型**，如图所示：
![](Pasted%20image%2020230924122059.png)
