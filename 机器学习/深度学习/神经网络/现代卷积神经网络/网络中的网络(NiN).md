[[../卷积神经网络/卷积层|卷积层]]的输入和输出由*四维张量*组成，张量的每个轴分别对应样本、通道、高度和宽度。而全连接层的输入和输出通常是分别对应于样本和特征的二维张量。

在[[../卷积神经网络/LeNet|LeNet]]、[[深度卷积神经网络(AlexNet)]]、[[使用块的网络(VGG)]]中，最后都是将卷积层压平后，通过全连接层输出输出，这会导致参数的急剧膨胀。
- 对于一个卷积层，其参数为：$输入通道数 \times 输出通道数 \times 数据分辨率$。
- 对于一个全连接层，则其参数为：$输入通道数 \times 卷积数据分辨率 \times 全连接分辨率$。
我们假设最后两层卷积参数为：$(1,512,7,7)$，对应的，其全连接参数为$(1, 4096)$。则可以得出，



NiN的想法是，在每个像素位置（针对每个高度和宽度）应用一个全连接层如果我们将权重连接到每个空间位置，我们可以将其视为[[../卷积神经网络/1*1卷积层|1*1卷积层]]，从另一个角度看，即将空间维度中的**每个像素视为单个样本**，将**通道维度视为不同特征**。

