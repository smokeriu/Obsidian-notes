在线性神经网络中，我们处理图像是直接平铺开，这对于小图片还行，然而对于稍大一点的照片，例如百万级像素的照片，如果按照线性神经的办法，则会拥有一百万个维度。

卷积的概念，来源于不变性：
- 平移不变性：不管检测对象出现在图像中的哪个位置，神经网络的前面几层应该对相同的图像区域具有相似的反应，即为“平移不变性”。
- 局部性：神经网络的前面几层应该只探索输入图像中的局部区域，而不过度在意图像中相隔较远区域的关系。


# 多层感知机的限制
首先，[多层感知机](多层感知机.md)的输入是二维图像$\mathbf{X}$，其*隐藏表示*$\mathbf{H}$在数学上是一个矩阵，在代码中表示为二维张量。为了方便理解，我们可以认为，无论是输入还是隐藏表示都拥有空间结构。

> 隐藏表示，即输入经过处理后的输出。

使用$[\mathbf{X}]_{i, j}$和$[\mathbf{H}]_{i, j}$分别表示输入图像和隐藏表示中位置$(x,j)$处的像素。为了使每个隐藏神经元都能接收到每个输入像素的信息，我们将参数从权重矩阵替换成*四阶*权重张量$\mathsf{W}$，并使用$\mathbf{U}$表示偏置参数，则可以得到公式：
$$
\begin{split}\begin{aligned} \left[\mathbf{H}\right]_{i, j} &= [\mathbf{U}]_{i, j} + \sum_k \sum_l[\mathsf{W}]_{i, j, k, l}  [\mathbf{X}]_{k, l}\\ &=  [\mathbf{U}]_{i, j} +
\sum_a \sum_b [\mathsf{V}]_{i, j, a, b}  [\mathbf{X}]_{i+a, j+b}.\end{aligned}\end{split}
$$
其中，第二个公式使用$a$和$b$替换了$k$和$l$，他们的关系是：
- $k = i+a$。
- $l = j+b$。
这么做的目的是，