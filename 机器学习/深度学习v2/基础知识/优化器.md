优化器主要有两类：随机梯度下降（SGD）和自适应学习率（Ada）。
# 随机梯度下降
随机梯度下降到理念是，当训练出现震荡时，此时减小学习率，使得模型可以快速收敛。

# 自适应学习率
自适应