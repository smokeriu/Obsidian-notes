通过`nn.RNN`方法来定义线性层：
```python
torch.nn.RNN(input_size, hidden_size, num_layers)
```
其中：
- `input_size`：输入的特征数。
- `hidden_size`：隐藏层中输出的特征大小。
- `num_layers`：隐藏层的个数。

> u

# 输入

输入`input`需要遵循如下形状：
$$
seqLen \times batchSize \times inputSize
$$
隐状态`h0`需要遵循如下形状：
$$
numLayers \times batchSize \times hiddenSize
$$
# 输出
输出`output`需要遵循如下形状：
$$
seqLen \times batchSize \times hiddenSize
$$
输出隐状态`hn`需要遵循如下形状：
$$
numLayers \times batchSize \times hiddenSize
$$
可以发现，输入和输出的形状只是将`input_size`变换为了`hidden_size`，而状态的形状是保持不变的。

# 使用
使用时，一般如下所示：
```python
output, hn = rnn(input, h0)
# rnn = nn.RNN(10, 20, 1)
# input = torch.randn(5, 3, 10)
# h0 = torch.randn(1, 3, 20)
# output = (5, 3, 20)
# hn = (5, 3, 10)
```

