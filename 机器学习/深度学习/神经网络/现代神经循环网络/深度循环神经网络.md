简单来说，深度循环神经网络，即是通过加深循环层层数，并配合其他层组合得到的神经网络，其如图所示：
![](Pasted%20image%2020230924100606.png|500)
> 上图中，横向表示$T$个时间步，而纵向表示$L$层。

我们假设时间步$t$时有一个小批量的输入数据$\mathbf{X}_t \in \mathbb{R}^{n \times d}$（$n$表示小批量的样本数，$d$表示每个样本的输入数），同时假设$l^{th}$隐藏层的隐状态为$\mathbf{H}_t^{(l)} \in \mathbb{R}^{n \times h}$（$h$表示为这一层的隐藏单元数），同时将输出设置为$\mathbf{O}_t \in \mathbb{R}^{n \times q}$（$q$表示输出个数），特别的，第0层的隐状态设置为$\mathbf{H}_t^{(0)} = \mathbf{X}_t$，同时假设第$l$个隐藏层的激活函数为$\phi_l$，则可以得到公式：
$$
\mathbf{H}_t^{(l)} = \phi_l(\mathbf{H}_t^{(l-1)} \mathbf{W}_{xh}^{(l)} + \mathbf{H}_{t-1}^{(l)} \mathbf{W}_{hh}^{(l)}  + \mathbf{b}_h^{(l)})
$$
其中参数均为第$l$层的模型参数：
- 权重$\mathbf{W}_{xh}^{(l)} \in \mathbb{R}^{h \times h}, \mathbf{W}_{hh}^{(l)} \in \mathbb{R}^{h \times h}$。
- 偏置$\mathbf{b}_h^{(l)} \in \mathbb{R}^{1 \times h}$。

则输出有：
$$
\mathbf{O}_t = \mathbf{H}_t^{(L)} \mathbf{W}_{hq} + \mathbf{b}_q,
$$
其中参数均为输出层的参数：
- 权重$\mathbf{W}_{hq} \in \mathbb{R}^{h \times q}$。
- 偏置$\mathbf{b}_q \in \mathbb{R}^{1 \times q}$。

特别的，隐藏层个数$L$和隐藏层的单元数目$h$都是超参数。