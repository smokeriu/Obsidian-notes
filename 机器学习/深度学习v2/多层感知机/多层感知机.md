多层感知机是最简单的神经网络，由3种类型的层构成：
- 输入层。
- 输出层。
- 隐藏层。

其用图形表示为：
![[assets/Pasted image 20231114190559.png|500]]
# 层
## 神经元
每一层由多个神经元构成。
## 输入层
输入层即是对输入的高维抽象。比如说一个单词，可以按照字母抽象成数值，最终拼接形成与单词长度一样的一维向量。每个神经元对应这向量中的一个元素。
## 隐藏层
用于对输入层输出的数据的不同特征进行高维抽象，一般而言，每个神经元负责的特征不同，具体负责哪方面的特征是程序自动洗得的。

> 其与输出层特征抽象后的位置相关。

## 输出层
对输出的数据与预期的标签数据进行映射，输出层的每个神经元需要与标签数据抽象的向量一一对应。
例如在识别数字的模型中，对于十进制的数字，显然是一个十分类的问题，则训练的输出生成一个长度为10的向量，训练的目的就是让程序根据*输入*与*标签*的关系，自动调整，使得最终输出的向量尽可能接近标签对应的向量。

## 前向传播
一般而言，层在接受到输入后，会经过一个线性变换：
$$
out = f(input) = w * input + b
$$
之后再经过[[../基础知识/激活函数|激活函数]]处理后作为下一层的输入：
$$
input2 = \alpha(output)
$$
当数据到达输出层时，再通过[[../基础知识/损失函数|损失函数]]计算损失值，通过反向传播优化参数，从而训练模型。